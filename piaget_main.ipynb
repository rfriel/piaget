{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.misc\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "from time import sleep\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-09 11:55:06,061] Making new env: MsPacman-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MsPacman-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_movers(s, s1, force_square=True):\n",
    "    movers = []\n",
    "    frame_diff = s1 - s\n",
    "    fd_grey = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(fd_grey,1,255,cv2.THRESH_BINARY)[1]\n",
    "    thresh_dilated = cv2.dilate(thresh,None,iterations=1)\n",
    "    (cnts, _) = cv2.findContours(thresh_dilated.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i, c in enumerate(cnts):\n",
    "        if cv2.contourArea(c) > 41:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            if force_square:\n",
    "                if w < h:\n",
    "                    deltaW = h - w\n",
    "                    w = h\n",
    "                    x = x - int(deltaW/2)\n",
    "                elif h < w:\n",
    "                    deltaH = w - h\n",
    "                    h = w\n",
    "                    y = y - int(deltaH/2)\n",
    "            if (x >= 0) and (y >= 0):\n",
    "                point0 = Point(x,y)\n",
    "                point1 = Point(x+w, y+h)\n",
    "                movers.append((point0, point1))\n",
    "    return movers, thresh_dilated\n",
    "\n",
    "def movers_mask(s, s1, shape):\n",
    "    movers = find_movers(s, s1)\n",
    "    mask = np.zeros(shape)\n",
    "    for m in movers:\n",
    "        mask[m[0]:m[1], m[2]:m[3]] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_pacman(env):\n",
    "    env.reset()\n",
    "    # nothing happens in first 100 steps of ms pacman\n",
    "    for i in range(100):\n",
    "        s,r,d,info = env.step(env.action_space.sample()) # take a random action\n",
    "    return s,info\n",
    "\n",
    "\n",
    "def dump_mover_images(num_steps, env, img_dir, debug=False):\n",
    "    \n",
    "    run_identifier = str(random.randint(0,1e6))\n",
    "    \n",
    "    s, info = init_pacman(env)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        if info['ale.lives'] == 0:\n",
    "            s, info = init_pacman(env)\n",
    "    \n",
    "        s1,r,d,info = env.step(env.action_space.sample())\n",
    "        \n",
    "        s = s[:160,:]\n",
    "        s1 = s1[:160,:]\n",
    "        \n",
    "        movers, thresh_dilated = find_movers(s, s1, force_square=True)\n",
    "        \n",
    "        for m in movers:\n",
    "            m_image = Image.fromarray(s[m[0]:m[1], m[2]:m[3]])\n",
    "            m_image.save(img_dir + run_identifier + 'img' + str(i) + '.jpg')\n",
    "            \n",
    "            if debug:\n",
    "                # figures for debugging\n",
    "                fig = plt.figure(figsize=(10,10))\n",
    "                fig.add_subplot(121)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(s[m[0]:m[1], m[2]:m[3]])\n",
    "                ax = fig.add_subplot(122)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(thresh_dilated)\n",
    "                ax.add_patch(patches.Rectangle((m[2]-1,m[0]-1),m[3]-m[2],m[1]-m[0],color='g',fill=False))\n",
    "\n",
    "                plt.show()\n",
    "                pdb.set_trace()\n",
    "        s = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __repr__(self):\n",
    "        return str((self.x, self.y))\n",
    "    \n",
    "    def sq_dist(self, p):\n",
    "        return (self.x-p.x)**2 + (self.y-p.y)**2\n",
    "\n",
    "class Mover():\n",
    "    def __init__(self, mover_id, game_id, img_dir):\n",
    "        self.trajectory = []\n",
    "        self.id = mover_id\n",
    "        self.img_dir = img_dir + 'mover' + str(self.id) + '/'\n",
    "        os.mkdir(self.img_dir)\n",
    "        self.features = None\n",
    "        \n",
    "    def add_observation(self, location, img):\n",
    "        self.trajectory.append(location)\n",
    "        img_for_save = Image.fromarray(img)\n",
    "        img_for_save.save(self.img_dir + str(random.randint(0,1e6)) + '.jpg')\n",
    "\n",
    "class MoverTracker():\n",
    "    def __init__(self, game_id, img_dir, hyperparams):\n",
    "        self.game_id = game_id\n",
    "        self.n_movers = 0\n",
    "        self.movers = []\n",
    "        self.action_hist = []\n",
    "        self.reward_hist = []\n",
    "        self.img_dir = img_dir + str(game_id) + '/'\n",
    "        os.mkdir(self.img_dir)\n",
    "        self.hyperparams = hyperparams\n",
    "        \n",
    "    def process_frame_pair(self, frame_pair):\n",
    "        self.action_hist.append(frame_pair.a)\n",
    "        self.reward_hist.append(frame_pair.r)\n",
    "        \n",
    "        boxes = find_movers(frame_pair.s0, frame_pair.s1, \\\n",
    "                            force_square=self.hyperparams['force_square'])[0]\n",
    "        if self.n_movers == 0:\n",
    "            for i, box in enumerate(boxes):\n",
    "                m = Mover(mover_id=i, game_id=self.game_id, img_dir=self.img_dir)\n",
    "                img = frame_pair.s0[box[0].y:box[1].y, box[0].x:box[1].x]\n",
    "                center = Point((box[0].x + box[1].x)/2, (box[0].y + box[1].y)/2)\n",
    "                \n",
    "                m.add_observation(center, img)\n",
    "                self.movers.append(m)\n",
    "                self.n_movers += 1\n",
    "        else:\n",
    "            cur_positions = [m.trajectory[-1] for m in self.movers]\n",
    "            internal_dists = self.get_internal_dists(cur_positions)\n",
    "            for i, box in enumerate(boxes):\n",
    "                img = frame_pair.s0[box[0].y:box[1].y, box[0].x:box[1].x]\n",
    "                center = Point((box[0].x + box[1].x)/2, (box[0].y + box[1].y)/2)\n",
    "                \n",
    "                box_id = self.identify_mover(center, cur_positions, internal_dists)\n",
    "                if box_id >= self.n_movers:\n",
    "                    # new mover\n",
    "                    m = Mover(mover_id=box_id, game_id=self.game_id, img_dir=self.img_dir)\n",
    "                    m.add_observation(center, img)\n",
    "                    self.movers.append(m)\n",
    "                    self.n_movers += 1\n",
    "                else:\n",
    "                    self.movers[box_id].add_observation(center, img)\n",
    "\n",
    "                \n",
    "    def identify_mover(self, center, cur_positions, internal_dists):\n",
    "        dists = [center.sq_dist(p) for p in cur_positions]\n",
    "        ind_min = np.argmin(dists)\n",
    "        if dists[ind_min] > np.percentile(internal_dists,0.33):\n",
    "            # above test is crude, refine later\n",
    "            # new mover\n",
    "            return self.n_movers\n",
    "        else:\n",
    "            return ind_min\n",
    "        \n",
    "    def get_internal_dists(self, cur_positions):\n",
    "        internal_dists = []\n",
    "        for i, p1 in enumerate(cur_positions):\n",
    "            for j, p2 in enumerate(cur_positions[:i]):\n",
    "                internal_dists.append(p1.sq_dist(p2))\n",
    "        return internal_dists\n",
    "    \n",
    "class FramePair():\n",
    "    def __init__(self, s0, s1, a, r):\n",
    "        self.s0 = s0\n",
    "        self.s1 = s1\n",
    "        self.a = a\n",
    "        self.r = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play(num_steps, env, img_dir, debug=False, hyperparams={'force_square':True}):\n",
    "    \n",
    "    game_id = str(random.randint(0,1e6))\n",
    "    \n",
    "    mover_tracker = MoverTracker(game_id, img_dir, hyperparams)\n",
    "    \n",
    "    s0, info = init_pacman(env)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        if info['ale.lives'] == 0:\n",
    "            s0, info = init_pacman(env)\n",
    "    \n",
    "        a = env.action_space.sample()\n",
    "        s1,r,d,info = env.step(a)\n",
    "        \n",
    "        s0 = s0[:160,:]\n",
    "        s1 = s1[:160,:]\n",
    "\n",
    "        frame_pair = FramePair(s0, s1, a, r)\n",
    "        \n",
    "        mover_tracker.process_frame_pair(frame_pair)\n",
    "        \n",
    "        s0 = s1\n",
    "    \n",
    "    return mover_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981749\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20\n",
    "img_dir = 'img/'\n",
    "mt = play(num_steps, env, img_dir)\n",
    "print mt.game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAxZJREFUeJzt2rFqw1AQRUFt8P//8qYK5Lgwbpwnwkxn4eJWhxVodvcC\n+PF1egBwL6IAhCgAIQpAiAIQogCEKAAhCkCIAhCP0wOu67pmxmeV8GG7O+/8z6UAhCgAIQpAiAIQ\nogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIA\nhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQo\nACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAh\nCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpA\niAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgC\nEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCi\nAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIArG71+6ensFBogDE4/QA7un3tTAzL38/P5uZ\nvxnJR8wdTsWZOT8C/rndfavWXh+AEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUg\nRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQB\nCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhR\nAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgZndPbwBu\nxKUAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCi\nAIQoACEKQHwDcc8k6xOQHRoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b15f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA0lJREFUeJzt3MFqg1AQQFFfyf//8nRV6A0WglQM5pxVCAZmk+sYg2tm\nNoAfX1cPALwXUQBCFIAQBSBEAQhRAEIUgBAFIEQBiMfVA2zbtq21/K0STjYz65XjbApAiAIQogCE\nKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgA\nIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEK\nQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCI\nAhCiAIQoACEKQIgCEKIAhCgAIQpAiAKHzMzVI3ASUeCQtdbVI3CSx9UD8L9m5s8v7O+z+1orx/68\n3tsAnt9//iz3YlMAYr3DteFa6/oh4OZm5qXVzqbAIe9wMuEcosAhfk+4L1EAQhQ4xOXDfYkCh7h8\nuC9RAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIESBXR6i8rlEAQhRYJcn\nK30uUQBCFIAQBSBEAQhRYJdbkp9LFIAQBXa5Jfm5RAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEA\nQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIU\ngBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQ\nBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUg\nRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQB\nCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAGINTNXzwC8EZsCEKIA\nhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQo\nAPENim828cddgpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e177d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA4FJREFUeJzt2sFq4zAUQFFr6P//8ptVoLcEGmZcbKXn7AJZvEV8LSla\nM3MAPPy5egDgXkQBCFEAQhSAEAUgRAEIUQBCFIAQBSA+rh7gOI5jreVaJfywmVmvfM9KAQhRAEIU\ngBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQ\nBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUg\nRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQB\nCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhR\nAEIUgBAFIEQBCFEAQhQ2NzNXj8CbEQUgRGFza62rR+DNiAIQorA5ZwqcTRSAEIXNOVPgbKKwuTtu\nH+44E68Thc3dcaWw1jpmRhw2JQpAiMLm7vo2XmvdchXD90Rhcx48ziYKQIgCp7vrlobXiAKns6XZ\nmyjwlLf97yUKQIgCT9kC/F6isLm7LvPdaNyXKGzup97o//tAu7y0L1EAQhSA+Lh6AN7H5y2HrcO+\nRIGn/uWhFoL3YPsAhCgAIQo89bhn8Dgn+PoX5efP7iO8F1EAYt2h8mut64fY1Mw44OMlM/PSD8VK\nYXOCwNlEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSA\nEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAF\nIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBE\nAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEI\nUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAYg1M1fPANyIlQIQogCE\nKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgA\n8Rea5lHn30cn9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e37f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAwtJREFUeJzt2jFqw1AQANG/Ife/8qayyRQGFw4S4T0QAukXW4hhC83u\nHoCHr6sHAO5FFIAQBSBEAQhRAEIUgBAFIEQBCFEA4vvqAc45Z2b8Vgl/bHfnnXM2BSBEAQhRAEIU\ngBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQ\nBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUg\nRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQB\nCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhR\nAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBC\nFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSA\nEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgROFmdvd5f1yv3v1+Bp8yd/ioZub6\nIeCf291555xNAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEA\nQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIU\ngBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQ\nBSBEAQhRAEIUgBAFIEQBCFEAQhSAEAUgRAEIUQBCFIAQBSBEAQhRAGJ29+oZgBuxKQAhCkCIAhCi\nAIQoACEKQIgCEKIAhCgAIQpAiAIQogCEKAAhCkCIAhCiAIQoACEKQIgCEKIAhCgAIQpAiAIQP5l3\nKtdRf8XaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115729ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in mt.movers:\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    darkFrame = np.zeros((160,160,3))\n",
    "\n",
    "    for p in m.trajectory:\n",
    "        darkFrame[int(p.y), int(p.x), :] = 1\n",
    "\n",
    "    plt.imshow(darkFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-534272e825fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'img/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdump_mover_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-44d63816a584>\u001b[0m in \u001b[0;36mdump_mover_images\u001b[0;34m(num_steps, env, img_dir, debug)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mm_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mm_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrun_identifier\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'img'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "num_steps = 200\n",
    "img_dir = 'img/'\n",
    "\n",
    "dump_mover_images(num_steps, env, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,9)\n",
    "\n",
    "s,r,d,info = env.step(a)\n",
    "\n",
    "a = np.random.randint(0,9)\n",
    "\n",
    "s1,r,d,info = env.step(a)\n",
    "\n",
    "a = np.random.randint(0,9)\n",
    "\n",
    "s2,r,d,info = env.step(a)\n",
    "\n",
    "plt.imshow(s1[:160,:])\n",
    "\n",
    "frame_diff = s1[:160,:]-s[:160,:]\n",
    "frame_diff_2 = s2[:160,:]-s1[:160,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAFkCAYAAAA5aB1DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAYmwAAGJsBSXWDlAAADqVJREFUeJzt3b2OJNUZBuBqi5uwMDEBFjFCAnEBzjZxxC2wGVyCyfYa\nHJE44wIsIyHHFgQbM2gvoxzYC7Mzb1X31NTP+U49T8RuT22fOnX608vXNacu4zgOAADAu/5w9AAA\nAKBFgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAA\nBIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAE7x09gCou\nl8t49BiAvo3jeDl6DFtSR4GtrV1HBeUb3X311dFDAChNHQWqcesFAAAEOsor+NM//nj0EA5z9+LN\n7Otnnpszm1sXZ18T1z4zZ3XmdaGOkqij0/asozrKAAAQCMoAABAIygAAEAjKAAAQCMoAABAIygAA\nEAjKAAAQ2Ed5Y0v3Qaxy3HNUOcct5qbKOVgXbc3NWVW5tj4v6uiaxz1HlXOsUEd1lAEAIBCUAQAg\nEJQBACC4jON49BhK+PXly8mJauU+miNce976mefmzCrcd3aUubl5/9Wry45D2Z06mqmjJOrotD3r\nqI4yAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAATvHT0Asmsb0C/RywblW8zN\nmVkX03qZm7OyJqapo+uyLqbNzU2Fh6oIyhursAgAAHjMrRcAABAIygAAEAjKAAAQCMoAABAIygAA\nEAjKAAAQ2B6OYRiO2cbO1nntsy7gdj4vJNZFbTrKAAAQCMoAABAIygAAELhHmWEYjrlnyX1S7bMu\n4HY+LyTWxbQK49RRBgCAQEd5YxX+bwkAgMd0lAEAIBCUAQAgEJQBACAQlAEAIBCUAQAgEJQBACCw\nPVyjqmwrZyN1EuuCFlRZEz4vJNZFG3SUAQAgEJQBACAQlAEAIBCUAQAgEJQBACAQlAEAIBCUAQAg\nEJQBACDwwJGN3b14M/na3MbePRx3xHu2dNycKudwxJxVGesW64KsyrVVR9XRFo474j1bWhdr01EG\nAIBAUAYAgOAyjuPRYyjh15cvJyeqla8HgPbNfdX4/qtXlx2Hsjt1FFjDnnVURxkAAAJBGQAAAkEZ\nAAACQRkAAAJBGQAAAkEZAAACQRkAAAJBGQAAgveOHkAP5ja+nrPFBvt7Pzd96blfU2msragyZ1s9\nWKKXtX9W6uj6Ko21FVXmTB3dj44yAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIA\nAAQeONKoljb93mpj86UqjbUVlebM2mct1tK0SmNtRaU5s/bXo6MMAACBoAwAAIFbLxq191cVlb4a\nqTTWVlSaM2uftVhL0yqNtRWV5szaX4+OMgAABIIyAAAEgjIAAASCMgAABIIyAAAEgjIAAASCMgAA\nBIIyAAAEHjhyo543036OSvNSaaytMGfTtpib8dXq/2RTrKes0rxUGmsrzNm0CnVURxkAAAIdZRiG\n4d9//ufka5/89MVu4wCoTj2lJzrKAAAQ6ChzanOdj4c/oxMCMO3WeqqWUomgzCk9LOj3C/dUMFbg\nAR57aj3VfKASt14AAECgowz3pK8Ob/k6EYDfTdVN9ZRqdJQBACDQUd7Y3Ys3k6/NbbS99Lilthjn\nc47d+ri71/lnPvnpi0cdjz99+OH/j3n96L2XXosjz73l45577BJVPqNnVuUana2O/vZ3oZ6+vf/4\nbT39/bgPh7vXr9/5O3V03eOee+wSVT6jS+goAwBAoKMMw/y9yVPdZwAeS/X0bRcZqrmM43j0GEq4\nfPBtiYmq8DVGC5b+QontjNrVw9off/n6cvQYtqSO9kk97UcPa3/tOurWCwAACARlAAAIBGUAAAgE\nZQAACARlAAAIBGVO7ZOfvnjnN68f/vfUawC8637NTPVz6jVomaAMAACBB45wSg+7GXOdY50PgGnq\nKT0TlG80twn3Untv3r3FOWxl72fR98Cc7cvcPJ06ui814enM2b4qzI1bLwAAIBCUAQAgEJQBACAQ\nlAEAIBCUAQAgEJQBACAQlAEAIBCUAQAg8MCRRs1twr33Bvut2WJuqszp0s3Zradp5qZfru00dXTd\n46qc+1Z6nhsdZQAACARlAAAIBGUAAAjco9yo6vf0bMncPJ05m2Zu+uXaTjM3T2fOpvU8NzrKAAAQ\nCMoAABAIygAAEAjKAAAQCMoAABAIygAAEAjKAAAQ2Ef5Rkv3CFz6TPmlet7LkP1ZT8ssnbfx1coD\naYw6yhlZT8u0Ukd1lAEAIBCUAQAgEJQBACAQlAEAIBCUAQAgsOsFHOD7L7+bfO0vf//rjiMBAKYI\nyrCjuYD88GcEZgA4llsvAAAg0FFu1NwG+3ObcLd03BHv2fLG7ve7yQ+7xd9/+V38u/SzS7S0Lq5d\no0pjpW1V1pI6usyPn300+dqnP/y8+vu1tC7U0f3oKAMAQKCjDAdK9yzfch8zwFnNdZIf/swWnWXO\nRUcZAAACHeVGLb2np8pxR71na97ef5zuX16zs2xdrH8c7auylip9Xo52v5v8sFv842cfxb9LP7uE\ndbH+cRXoKAMAQKCjDAdwbzLAOtI9y7fcxwy30FEGAMr69IefH91akf4OlhCUAQAgcOsFAFCOWy7Y\ng44yAAAEgjIAAASCMgAABO5RvtHdizdHD+EmVcZ5Ta+blz98mMj9P0+9diTraZle5m1tVealyjiv\n6bWOVmM9LdPKvAnKsJP7wfdhCJ57DQA4hlsvAAAg0FEGAMp4+yCRt1vB3f/z1GuwlI4yAAAEOsoA\nQAn3O8TpsdVTr8FSOsoAABAIygAAELj1olFz+weefW9Mc/N05myauemXazvN3DydOZvW89zoKAMA\nQCAoAwBAICgDAEDgHuVGVb+nZ0tbzE0rz5TfivU0zdz0y7Wdpo4+nfU0ree50VEGAIBAUAYAgEBQ\nBgCAQFAGAIBAUAYAgEBQBgCAQFAGAIBAUAYAgOAyjuPRYyjh8sG3JSZqbsP3njcEhx7W/vjL15ej\nx7AldRTa1sPaX7uOejIfHOg/f/vXMAzD8PE3n//23w99/M3new4JoGn36+b9P9+nbrIWt14AAECg\nowwHuKUjcv9ndUcA3q2H1+rmMOgs83w6ygAAEOgowwFSR2SuS6I7ApB/n+OWDjMspaMMAACBjjI0\nQjcE4OnSN3OwFh1lAAAIdJQ3tnTz7h42/aYde6/D56zfvde+z2j7XCPm7NVFVkfXf78Kn1EdZQAA\nCARlAAAILuM4Hj2GEi4ffFtioip8jcHvnvoLfH5RZVoPa3/85evL0WPYkjrKGubqphr5PD2s/bXr\nqI4yAAAEfpkPAOjC1MNIYCkdZQAACHSU4UC3PnpVVwTgfzyymj3pKEMD5oKwkAzw2MfffD5ZH+de\ng6cQlAEAIHDrBTRC9wPg6dROtqSjDAAAgY7yjeY24V6qyubdc67NS0vPlN/i/bbQ+5z1sO6HYf91\n0QN1NFNH19f7nPWw7oehRh3VUQYAgEBQBgCAQFAGAIBAUAYAgEBQBgCAQFAGAIBAUAYAgEBQBgCA\nwANHGnWGjcb31sOcnmHD+zOcI/twbdfXw5yeocac4Rz3oqMMAACBoAwAAIFbLxpV/auKFvUwp3uf\nwxFzdoZzZB+u7fp6mNMz1JgznONedJQBACAQlAEAIBCUAQAgEJQBACAQlAEAIBCUAQAgEJQBACAQ\nlAEAIPDAkRW0tNF2S2PphTmtocoG+3cv3qw8kj609DlraSy9MKc1qKOP6SgDAEAgKAMAQCAoAwBA\nICgDAEAgKAMAQCAoAwBAICgDAEAgKAMAQOCBIxub2xR7bqPtvY87wt5jbWlOWxrLnCPWU5XPTKXP\nWnWu7bQqNUEd3e/9nvOeVY7bk44yAAAEgjIAAARuvdjY0q8O9j7uCFWeKb/FOFsaS0vv95z3rHIc\nT+faTqtSE9TRfVX5zFT4rOkoAwBAICgDAEAgKAMAQCAoAwBAICgDAEAgKAMAQCAoAwBAICgDAEDg\ngSONmnv++VIVNva+xd7nscW1mNPSxvyV+MzwkDUxTR1t499sjc/MYzrKAAAQCMoAABAIygAAEAjK\nAAAQCMoAABAIygAAEAjKAAAQCMoAABB44MjG5jbvbmkT7iPGufQ99z6uJWeYsyrXqco4e1Blrit9\nXirVhLWdYc6qXKcK49RRBgCAQFAGAIBAUAYAgMA9yhtr5R6ba44Y59L33Pu4lpxhzqpcpyrj7EGV\nua70ealUE9Z2hjmrcp0qjFNHGQAAAkEZAAACQRkAAAJBGQAAAkEZAAACQRkAAAJBGQAAAvsos6m5\n57hvocKejEfY+zoA61FH26COrm9uTltZhzrKAAAQ6ChvrML/LQEA8JiOMgAABIIyAAAEgjIAAASC\nMgAABIIyAAAEgjIAAAS2h2MYhnNsY9fDOfZwDtec4Rzp0xnWbg/n2MM5XHOGc9yLjjIAAASCMgAA\nBIIyAAAE7lFmGIZz3LPUwzn2cA7XnOEc6dMZ1m4P59jDOVxT5RwrjFNQ3liFRQAAwGNuvQAAgEBQ\nBgCAQFAGAIBAUAYAgEBQBgCAQFAGAIDA9nCNqrKtXJVxPkcP59jDOVxzhnPkaaqsiSrjfI4ezrGH\nc7jmDOf4VDrKAAAQCMoAABAIygAAEFzGcTx6DAAA0BwdZQAACARlAAAIBGUAAAgEZQAACARlAAAI\nBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARl\nAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAA\nCARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgE\nZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUAAAgEZQAACARlAAAIBGUA\nAAj+C78O6nykhgJlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113842710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "107.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFgCAYAAABJzuRWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1126eb610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "112.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHRCAYAAACYWCSGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112386bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9f102989be1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#plt.imshow(thresh[y:y+h,x:x+w])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_subplots.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, axisbg, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# a dict from events to (id, func)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# funcs used to format x and y - fall back on major formatters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt_xdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mspine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_existing_data_limits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/spines.pyc\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m  \u001b[0;31m# clear position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_frame_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mreset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lastNumMajorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m_get_tick2line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                           \u001b[0mmarkeredgewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                           zorder=self._zorder)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tick2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m#convert sequences to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xdata must be a sequence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/cbook.pyc\u001b[0m in \u001b[0;36miterable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;34m\"\"\"return true if *obj* is iterable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114009290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test=cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(test,1,255,cv2.THRESH_BINARY)[1]\n",
    "thresh_dilated = cv2.dilate(thresh,None,iterations=1)\n",
    "(cnts, _) = cv2.findContours(thresh_dilated.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "thresh = cv2.cvtColor(thresh,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5),dpi=160)\n",
    "fig.add_subplot(121)\n",
    "plt.axis('off')\n",
    "plt.imshow(s1[:160,:])\n",
    "fig.add_subplot(122)\n",
    "plt.imshow(s[:160,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "objects = []\n",
    "movers = find_movers(s, s1)\n",
    "\n",
    "for i, c in enumerate(cnts):\n",
    "    if cv2.contourArea(c) > 41:\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        fig = plt.figure(figsize=(5,5),dpi=160)\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.axis('off')\n",
    "        #plt.imshow(thresh[y:y+h,x:x+w])\n",
    "        plt.imshow(thresh)\n",
    "        print i\n",
    "        print cv2.contourArea(c)\n",
    "        plt.axis([1, 160, 160, 1])\n",
    "        ax.add_patch(patches.Rectangle((x,y),w,h,color='g',fill=False))\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(s[y:y+h,x:x+w])\n",
    "        objects.append(s[y:y+h,x:x+w])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(s[y:y+h,x:x+w])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "net = DynNetwork()\n",
    "\n",
    "sess.run(tf.variables_initializer(tf.global_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DynNetwork():\n",
    "    def __init__(self):\n",
    "        #self.scalarInputFrame0 =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        #self.imageInFrame0 = tf.reshape(self.scalarInputFrame0,shape=[-1,84,84,3])\n",
    "\n",
    "        #self.scalarInputFrame1 =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        #self.imageInFrame1 = tf.reshape(self.scalarInputFrame1,shape=[-1,84,84,3])\n",
    "        \n",
    "        self.imageInFrame0 = tf.placeholder(shape=[1,160,160,3],dtype=tf.float32,name='imageInFrame0')\n",
    "        self.imageInFrame1 = tf.placeholder(shape=[1,160,160,3],dtype=tf.float32,name='imageInFrame1')\n",
    "\n",
    "        #self.action = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "        \n",
    "        with tf.variable_scope('conv1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([4, 4, 3, 16], dtype=tf.float32,\\\n",
    "                                               stddev=1e-1))\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[16], dtype=tf.float32),\n",
    "                           trainable=True)\n",
    "\n",
    "            conv_F0 = tf.nn.conv2d(self.imageInFrame0, kernel, [1, 2, 2, 1], padding='SAME')\n",
    "            conv_F1 = tf.nn.conv2d(self.imageInFrame1, kernel, [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            bias_F0 = tf.nn.bias_add(conv_F0, biases)\n",
    "            bias_F1 = tf.nn.bias_add(conv_F1, biases)\n",
    "\n",
    "            self.conv1_F0 = tf.nn.relu(bias_F0,name=scope.name)\n",
    "            self.conv1_F1 = tf.nn.relu(bias_F1,name=scope.name)\n",
    "\n",
    "        with tf.variable_scope('conv2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([4, 4, 16, 8], dtype=tf.float32,\\\n",
    "                                               stddev=1e-1))\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[8], dtype=tf.float32),\n",
    "                           trainable=True)\n",
    "\n",
    "            conv_F0 = tf.nn.conv2d(self.conv1_F0, kernel, [1, 2, 2, 1], padding='SAME')\n",
    "            conv_F1 = tf.nn.conv2d(self.conv1_F1, kernel, [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "            bias_F0 = tf.nn.bias_add(conv_F0, biases)\n",
    "            bias_F1 = tf.nn.bias_add(conv_F1, biases)\n",
    "\n",
    "            self.conv2_F0 = tf.nn.relu(bias_F0,name=scope.name)\n",
    "            self.conv2_F1 = tf.nn.relu(bias_F1,name=scope.name)\n",
    "        '''\n",
    "        with tf.variable_scope('conv3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 8], dtype=tf.float32,\\\n",
    "                                               stddev=1e-1))\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[8], dtype=tf.float32),\n",
    "                           trainable=True)\n",
    "\n",
    "            conv_F0 = tf.nn.conv2d(self.conv2_F0, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            conv_F1 = tf.nn.conv2d(self.conv2_F1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            bias_F0 = tf.nn.bias_add(conv_F0, biases)\n",
    "            bias_F1 = tf.nn.bias_add(conv_F1, biases)\n",
    "\n",
    "            self.conv3_F0 = tf.nn.relu(bias_F0,name=scope.name)\n",
    "            self.conv3_F1 = tf.nn.relu(bias_F1,name=scope.name)\n",
    "        \n",
    "        '''\n",
    "        with tf.variable_scope('conv_diff') as scope:\n",
    "            nonzero_weightsF0 = tf.Variable(tf.truncated_normal([2, 2, 8], dtype=tf.float32,\\\n",
    "                                                                    stddev=1e-1), name='nonzero_weightsF0')\n",
    "            nonzero_weightsF1 = tf.Variable(tf.truncated_normal([2, 2, 8], dtype=tf.float32,\\\n",
    "                                                                    stddev=1e-1), name='nonzero_weightsF1')\n",
    "            weightsF0 = tf.matrix_set_diag(tf.zeros([2,2,8,8]),nonzero_weightsF0)\n",
    "            weightsF1 = tf.matrix_set_diag(tf.zeros([2,2,8,8]),nonzero_weightsF1)\n",
    "            kernel = tf.concat([weightsF0,weightsF1],2)\n",
    "            \n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[8], dtype=tf.float32),\n",
    "                           trainable=True)\n",
    "            conv2_both = tf.concat([self.conv2_F0, self.conv2_F1],3)\n",
    "            \n",
    "            conv = tf.nn.conv2d(conv2_both, kernel, [1, 2, 2, 1], padding='SAME')\n",
    "            \n",
    "            bias = tf.nn.bias_add(conv, biases)\n",
    "            self.conv_diff = tf.nn.relu(bias, name=scope.name)\n",
    "        \n",
    "        #self.cdf = slim.flatten(self.conv_diff)\n",
    "        #self.fc = slim.fully_connected(self.cdf, 3)\n",
    "        #self.logits = tf.concat([self.fc, [[1]]],1)\n",
    "        \n",
    "        self.movers_mask = tf.placeholder(shape=[1,160,160,1],dtype=tf.float32)\n",
    "        #self.frame_diff_scalar = tf.reshape(self.frame_diff,[1,21168])\n",
    "        \n",
    "        nonzero_weightsOut = tf.Variable(tf.truncated_normal([8,8,8,1], dtype=tf.float32,\\\n",
    "                                                                stddev=1e-1), name='nonzero_weightsOut')\n",
    "\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[1,160,160,1], dtype=tf.float32),\n",
    "                           trainable=True)\n",
    "        \n",
    "        weightsProd = tf.tensordot(self.conv_diff, nonzero_weightsOut, [[3],[0]])\n",
    "\n",
    "        \n",
    "        channels = tf.unstack(weightsProd,axis=5)\n",
    "        screen_channels = []\n",
    "        for ch in channels:\n",
    "            full_cols=[tf.reshape(t,[160,8]) for t in tf.unstack(ch,axis=1)]\n",
    "            screen_channels.append(tf.concat(full_cols,1))\n",
    "        weightsProd_screen = tf.stack(screen_channels,axis=2)\n",
    "        \n",
    "        bias = tf.add(weightsProd_screen, biases)\n",
    "            \n",
    "        self.out = tf.nn.relu(bias, name=scope.name)\n",
    "\n",
    "        #self.loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.action, logits=self.logits))\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.movers_mask - self.out))\n",
    "        \n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.update_model = self.trainer.minimize(self.loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_steps = 50000\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# nothing happens in first 100 steps of ms pacman\n",
    "for i in range(100):\n",
    "    s,r,d,info = env.step(env.action_space.sample()) # take a random action\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    \n",
    "    if info['ale.lives'] == 0:\n",
    "        s = env.reset()\n",
    "        for i in range(100):\n",
    "            s,r,d,info = env.step(env.action_space.sample()) # take a random action\n",
    "\n",
    "    a = np.random.randint(0,9)\n",
    "    s1,r,d,info = env.step(a)\n",
    "\n",
    "    s = s[:160,:]\n",
    "    s1 = s1[:160,:]\n",
    "    \n",
    "    mask = np.expand_dims(movers_mask(s, s1, s.shape[:2]),2)\n",
    "    [dummy, loss] = sess.run([net.update_model, net.loss], \\\n",
    "                             feed_dict={net.imageInFrame0:[s],\\\n",
    "                                        net.imageInFrame1:[s1],\\\n",
    "                                        net.movers_mask: [mask]})\n",
    "    losses.append(loss)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print i\n",
    "        print losses[i]\n",
    "        \n",
    "        out = sess.run(tf.reshape(net.out,[160,160,1]), \\\n",
    "                             feed_dict={net.imageInFrame0:[s],\\\n",
    "                                        net.imageInFrame1:[s1],\\\n",
    "                                        net.movers_mask: [mask]})\n",
    "        out_im = np.reshape(out,s.shape[:2])\n",
    "        mask_im = np.reshape(mask,s.shape[:2])\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.subplot(121)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(out_im,cmap='gray')\n",
    "        plt.subplot(122)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mask_im,cmap='gray')\n",
    "        \n",
    "        plt.show()\n",
    "        pdb.set_trace()\n",
    "        \n",
    "    s = s1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses[100:],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_centers(env, num_steps, debug=False):\n",
    "    s, info = init_pacman(env)\n",
    "\n",
    "    centers = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        if info['ale.lives'] == 0:\n",
    "            s, info = init_pacman(env)\n",
    "    \n",
    "        s1,r,d,info = env.step(env.action_space.sample())\n",
    "        \n",
    "        s = s[:160,:]\n",
    "        s1 = s1[:160,:]\n",
    "        \n",
    "        movers, thresh_dilated = find_movers(s, s1, force_square=False)\n",
    "        \n",
    "        if debug:\n",
    "            fig = plt.figure(figsize=(10,10))\n",
    "            fig.add_subplot(121)\n",
    "            plt.imshow(s)\n",
    "            fig.add_subplot(122)\n",
    "            plt.imshow(s,alpha=0.5)\n",
    "            plt.imshow(s1,alpha=0.5)\n",
    "\n",
    "        curCenters = []\n",
    "        \n",
    "        for i, m in enumerate(movers):\n",
    "            if debug:\n",
    "                fig = plt.figure(figsize=(10,10))\n",
    "                fig.add_subplot(121)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(s[m[0]:m[1], m[2]:m[3]])\n",
    "                ax = fig.add_subplot(122)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(thresh_dilated)\n",
    "                ax.add_patch(patches.Rectangle((m[2]-1,m[0]-1),m[3]-m[2],m[1]-m[0],color='g',fill=False))\n",
    "                print 'Mover ' + str(i) + '\\n' + 'Center: ' + str( (centerX, centerY) )\n",
    "                plt.show()\n",
    "            \n",
    "            centerX = m[2] + (m[3]-m[2])/2; centerY = m[0] + (m[1]-m[0])/2\n",
    "            curCenters.append((centerX,centerY))\n",
    "\n",
    "\n",
    "        if debug:\n",
    "            fig = plt.figure(figsize=(10,10))\n",
    "            fig.add_subplot(121)\n",
    "            plt.axis('off')\n",
    "            darkFrame = np.zeros((160,160,3))\n",
    "            frame_colors = {0: [1,0,0], 1:[0,1,0]}\n",
    "            for frame_num, frame in enumerate(centers[-2:]):\n",
    "                for center in frame:\n",
    "                    darkFrame[int(center[1]),int(center[0]),:] = frame_colors[frame_num]\n",
    "            plt.imshow(darkFrame)\n",
    "\n",
    "            plt.show()\n",
    "            pdb.set_trace()\n",
    "        \n",
    "        \n",
    "        centers.append(curCenters)\n",
    "        s = s1\n",
    "    return centers"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
